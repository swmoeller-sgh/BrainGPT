result:
 {'question': 'What is unique about LLM?', 'result': {'answer': ' LLM is unique because it is an interdisciplinary dialogue between the best representatives of each field, which allows participants to open up to each other without having to prove their status to each other. It is also sponsored by the Josiah Macy Jr. Foundation and is robust enough to work with top managers, small businesses, NGOs, and even illiterate people.', 'source_documents': [Document(page_content='es vielleicht ein Kompetenzzentrum oder eine Expertengruppe, die voneinander lernt \nund gemeinsam Probleme löst.', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}), Document(page_content='Am Ende liegt in jedem der 12 Themen eine Antwort auf die Eröffnungsfrage vor, die \nsich wie Puzzle-Bausteine zu einem Gesamtbild zusammenfügen. Alle relevanten Per-\nspektiven sind in diese Antwort eingeflossen. Das Resultat ist umsetzbar, weil es umfas-\nsend und konkret ist und von dreißig Schlüsselpersonen nicht nur verstanden, sondern \nauch  gewollt  wird.  In  meinen  persönlichen  Erfahrungen  aus  über  zweihundert  solcher \nKlausuren auf allen Erdteilen und in allen verschiedenen Arten von Unternehmen und \nKulturen wurden die Erwartungen jedes Mal positiv übertroffen. Die Methode ist so ro-\nbust, dass sie mit Topmanagern auf Konzernebene genauso funktioniert wie in Bundes-\nministerien, in KMUs mit ganz praktisch denkenden Leuten, in wissenschaftlich orien-\ntierten NGOs oder gar mit Analphabeten. Sie ist weder abhängig von Technologie, noch \nvon  Kreativitätstechniken,  besonders  guten  Moderatoren  oder  von  besonders  diszipli-', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}), Document(page_content='übergreifenden  Gesprächszirkel.  Das  ist  ungewöhnlich.  Normalerweise  finden  sich  nur \nVertreter desselben Fachgebietes zu Gesprächen zusammen. Dieser interdisziplinäre Dia-\nlog wird zwischen 1946 und 1953\xa0in einer von der Josiah Macy Jr. Foundation gesponser-\nten Serie von zehn Konferenzen weitergeführt. Es werden nur die Besten aus jedem Fach-\ngebiet  zu  den  Gesprächen  zugelassen,  damit  sich  die Teilnehmer  nicht  erst  gegenseitig \nihren Status beweisen müssen und in Verteidigungshaltung gehen, wie das so oft geschieht. \nSie sollen sich einander öffnen. McCulloch ist als Vorsitzender dieser  Konferenzen sorg-', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}), Document(page_content='Glossar\n\nHomöostat \nKomplexität \n\nKontrolle (Selbst-) \n\nKybernetischer Imperativ \n\nLaw \nLaw of Cohesion \n\nLeadership \n\nManagement \n\nMillersche Zahl \n\nOperative Einheit \n\n343', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'})]}}
<class 'dict'>


result keys: dict_keys(['question', 'result'])


result["result"]["source_documents"]
 [Document(page_content='es vielleicht ein Kompetenzzentrum oder eine Expertengruppe, die voneinander lernt \nund gemeinsam Probleme löst.', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}), Document(page_content='Am Ende liegt in jedem der 12 Themen eine Antwort auf die Eröffnungsfrage vor, die \nsich wie Puzzle-Bausteine zu einem Gesamtbild zusammenfügen. Alle relevanten Per-\nspektiven sind in diese Antwort eingeflossen. Das Resultat ist umsetzbar, weil es umfas-\nsend und konkret ist und von dreißig Schlüsselpersonen nicht nur verstanden, sondern \nauch  gewollt  wird.  In  meinen  persönlichen  Erfahrungen  aus  über  zweihundert  solcher \nKlausuren auf allen Erdteilen und in allen verschiedenen Arten von Unternehmen und \nKulturen wurden die Erwartungen jedes Mal positiv übertroffen. Die Methode ist so ro-\nbust, dass sie mit Topmanagern auf Konzernebene genauso funktioniert wie in Bundes-\nministerien, in KMUs mit ganz praktisch denkenden Leuten, in wissenschaftlich orien-\ntierten NGOs oder gar mit Analphabeten. Sie ist weder abhängig von Technologie, noch \nvon  Kreativitätstechniken,  besonders  guten  Moderatoren  oder  von  besonders  diszipli-', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}), Document(page_content='übergreifenden  Gesprächszirkel.  Das  ist  ungewöhnlich.  Normalerweise  finden  sich  nur \nVertreter desselben Fachgebietes zu Gesprächen zusammen. Dieser interdisziplinäre Dia-\nlog wird zwischen 1946 und 1953\xa0in einer von der Josiah Macy Jr. Foundation gesponser-\nten Serie von zehn Konferenzen weitergeführt. Es werden nur die Besten aus jedem Fach-\ngebiet  zu  den  Gesprächen  zugelassen,  damit  sich  die Teilnehmer  nicht  erst  gegenseitig \nihren Status beweisen müssen und in Verteidigungshaltung gehen, wie das so oft geschieht. \nSie sollen sich einander öffnen. McCulloch ist als Vorsitzender dieser  Konferenzen sorg-', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}), Document(page_content='Glossar\n\nHomöostat \nKomplexität \n\nKontrolle (Selbst-) \n\nKybernetischer Imperativ \n\nLaw \nLaw of Cohesion \n\nLeadership \n\nManagement \n\nMillersche Zahl \n\nOperative Einheit \n\n343', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'})]


result["result"]["source_documents"][0]
 page_content='es vielleicht ein Kompetenzzentrum oder eine Expertengruppe, die voneinander lernt \nund gemeinsam Probleme löst.' metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}
<class 'langchain.schema.document.Document'>


result["result"]["source_documents"][0].page_content
 es vielleicht ein Kompetenzzentrum oder eine Expertengruppe, die voneinander lernt 
und gemeinsam Probleme löst.
<class 'str'>
result:
 {'question': 'What is unique about LLM?', 'result': {'answer': ' LLM is unique because it is an interdisciplinary dialogue between the best representatives of each field, which allows participants to open up to each other without having to prove their status to each other. It is also sponsored by the Josiah Macy Jr. Foundation and is robust enough to work with top managers, small businesses, NGOs, and even illiterate people.', 'source_documents': [Document(page_content='es vielleicht ein Kompetenzzentrum oder eine Expertengruppe, die voneinander lernt \nund gemeinsam Probleme löst.', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}), Document(page_content='Am Ende liegt in jedem der 12 Themen eine Antwort auf die Eröffnungsfrage vor, die \nsich wie Puzzle-Bausteine zu einem Gesamtbild zusammenfügen. Alle relevanten Per-\nspektiven sind in diese Antwort eingeflossen. Das Resultat ist umsetzbar, weil es umfas-\nsend und konkret ist und von dreißig Schlüsselpersonen nicht nur verstanden, sondern \nauch  gewollt  wird.  In  meinen  persönlichen  Erfahrungen  aus  über  zweihundert  solcher \nKlausuren auf allen Erdteilen und in allen verschiedenen Arten von Unternehmen und \nKulturen wurden die Erwartungen jedes Mal positiv übertroffen. Die Methode ist so ro-\nbust, dass sie mit Topmanagern auf Konzernebene genauso funktioniert wie in Bundes-\nministerien, in KMUs mit ganz praktisch denkenden Leuten, in wissenschaftlich orien-\ntierten NGOs oder gar mit Analphabeten. Sie ist weder abhängig von Technologie, noch \nvon  Kreativitätstechniken,  besonders  guten  Moderatoren  oder  von  besonders  diszipli-', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}), Document(page_content='übergreifenden  Gesprächszirkel.  Das  ist  ungewöhnlich.  Normalerweise  finden  sich  nur \nVertreter desselben Fachgebietes zu Gesprächen zusammen. Dieser interdisziplinäre Dia-\nlog wird zwischen 1946 und 1953\xa0in einer von der Josiah Macy Jr. Foundation gesponser-\nten Serie von zehn Konferenzen weitergeführt. Es werden nur die Besten aus jedem Fach-\ngebiet  zu  den  Gesprächen  zugelassen,  damit  sich  die Teilnehmer  nicht  erst  gegenseitig \nihren Status beweisen müssen und in Verteidigungshaltung gehen, wie das so oft geschieht. \nSie sollen sich einander öffnen. McCulloch ist als Vorsitzender dieser  Konferenzen sorg-', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}), Document(page_content='Glossar\n\nHomöostat \nKomplexität \n\nKontrolle (Selbst-) \n\nKybernetischer Imperativ \n\nLaw \nLaw of Cohesion \n\nLeadership \n\nManagement \n\nMillersche Zahl \n\nOperative Einheit \n\n343', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'})]}}
<class 'dict'>


result keys: dict_keys(['question', 'result'])


result["result"]["source_documents"]
 [Document(page_content='es vielleicht ein Kompetenzzentrum oder eine Expertengruppe, die voneinander lernt \nund gemeinsam Probleme löst.', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}), Document(page_content='Am Ende liegt in jedem der 12 Themen eine Antwort auf die Eröffnungsfrage vor, die \nsich wie Puzzle-Bausteine zu einem Gesamtbild zusammenfügen. Alle relevanten Per-\nspektiven sind in diese Antwort eingeflossen. Das Resultat ist umsetzbar, weil es umfas-\nsend und konkret ist und von dreißig Schlüsselpersonen nicht nur verstanden, sondern \nauch  gewollt  wird.  In  meinen  persönlichen  Erfahrungen  aus  über  zweihundert  solcher \nKlausuren auf allen Erdteilen und in allen verschiedenen Arten von Unternehmen und \nKulturen wurden die Erwartungen jedes Mal positiv übertroffen. Die Methode ist so ro-\nbust, dass sie mit Topmanagern auf Konzernebene genauso funktioniert wie in Bundes-\nministerien, in KMUs mit ganz praktisch denkenden Leuten, in wissenschaftlich orien-\ntierten NGOs oder gar mit Analphabeten. Sie ist weder abhängig von Technologie, noch \nvon  Kreativitätstechniken,  besonders  guten  Moderatoren  oder  von  besonders  diszipli-', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}), Document(page_content='übergreifenden  Gesprächszirkel.  Das  ist  ungewöhnlich.  Normalerweise  finden  sich  nur \nVertreter desselben Fachgebietes zu Gesprächen zusammen. Dieser interdisziplinäre Dia-\nlog wird zwischen 1946 und 1953\xa0in einer von der Josiah Macy Jr. Foundation gesponser-\nten Serie von zehn Konferenzen weitergeführt. Es werden nur die Besten aus jedem Fach-\ngebiet  zu  den  Gesprächen  zugelassen,  damit  sich  die Teilnehmer  nicht  erst  gegenseitig \nihren Status beweisen müssen und in Verteidigungshaltung gehen, wie das so oft geschieht. \nSie sollen sich einander öffnen. McCulloch ist als Vorsitzender dieser  Konferenzen sorg-', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}), Document(page_content='Glossar\n\nHomöostat \nKomplexität \n\nKontrolle (Selbst-) \n\nKybernetischer Imperativ \n\nLaw \nLaw of Cohesion \n\nLeadership \n\nManagement \n\nMillersche Zahl \n\nOperative Einheit \n\n343', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'})]


result["result"]["source_documents"][0]
 page_content='es vielleicht ein Kompetenzzentrum oder eine Expertengruppe, die voneinander lernt \nund gemeinsam Probleme löst.' metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}
<class 'langchain.schema.document.Document'>


result["result"]["source_documents"][0].page_content
 es vielleicht ein Kompetenzzentrum oder eine Expertengruppe, die voneinander lernt 
und gemeinsam Probleme löst.
<class 'str'>
result:
 {'question': 'What means LLM', 'result': {'answer': ' Large Language Models', 'source_documents': [Document(page_content='34', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}), Document(page_content='76', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}), Document(page_content='Verhältnismäßigkeit darstellen kann (Strubell et al., Energy and Policy Considerations for Deep \n\nLearning in NLP, MIT Technology Review 2019; zum rechtlichen Rahmen s. Rodi, HdB \n\nKlimaschutzrecht/Saurer et al., § 19 Rn. 18 ff.). Schließlich bestehen auch Bedenken, dass Large \n\nLanguage Models für haftungsrechtliche Probleme bei deren Primär- wie Sekundärnutzung sowie für \n\nVerstöße gegen Urheber-, Straf- oder Datenschutzrecht sorgen könnten (Hilgendorf et al, FAZ v. \n\n9.1.2023; Papastefanou CR 2023, 1 (1 ff.)). So zeigten etwa Tests an einer Vorgängerversion von \n\nChatGPT, dass diese unbeabsichtigt personenbezogenen Trainingsdaten preisgab (Carlini et al., \n\nExtracting Training Data from Large Language Models, UsenixSec, 2021).\n\nIII. Pflichtenkreis für Large Language Models nach dem DSA sowie dem AIA-E\n\nUnmittelbar werden Large Language Models oder deren Erzeugnisse weder im Digital Services Act', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Glossar\n\nHomöostat \nKomplexität \n\nKontrolle (Selbst-) \n\nKybernetischer Imperativ \n\nLaw \nLaw of Cohesion \n\nLeadership \n\nManagement \n\nMillersche Zahl \n\nOperative Einheit \n\n343', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'})]}}
<class 'dict'>


result keys: dict_keys(['question', 'result'])


result["result"]["source_documents"]
 [Document(page_content='34', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}), Document(page_content='76', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}), Document(page_content='Verhältnismäßigkeit darstellen kann (Strubell et al., Energy and Policy Considerations for Deep \n\nLearning in NLP, MIT Technology Review 2019; zum rechtlichen Rahmen s. Rodi, HdB \n\nKlimaschutzrecht/Saurer et al., § 19 Rn. 18 ff.). Schließlich bestehen auch Bedenken, dass Large \n\nLanguage Models für haftungsrechtliche Probleme bei deren Primär- wie Sekundärnutzung sowie für \n\nVerstöße gegen Urheber-, Straf- oder Datenschutzrecht sorgen könnten (Hilgendorf et al, FAZ v. \n\n9.1.2023; Papastefanou CR 2023, 1 (1 ff.)). So zeigten etwa Tests an einer Vorgängerversion von \n\nChatGPT, dass diese unbeabsichtigt personenbezogenen Trainingsdaten preisgab (Carlini et al., \n\nExtracting Training Data from Large Language Models, UsenixSec, 2021).\n\nIII. Pflichtenkreis für Large Language Models nach dem DSA sowie dem AIA-E\n\nUnmittelbar werden Large Language Models oder deren Erzeugnisse weder im Digital Services Act', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Glossar\n\nHomöostat \nKomplexität \n\nKontrolle (Selbst-) \n\nKybernetischer Imperativ \n\nLaw \nLaw of Cohesion \n\nLeadership \n\nManagement \n\nMillersche Zahl \n\nOperative Einheit \n\n343', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'})]


result["result"]["source_documents"][0]
 page_content='34' metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'}
<class 'langchain.schema.document.Document'>


result["result"]["source_documents"][0].page_content
 34
<class 'str'>
result:
 {'question': 'What is a large language model?', 'result': {'answer': ' A large language model is a type of artificial neural network that is used to process language or text inputs, such as in the context of machine translation or for language and text generation. They often work on the basis of feedforward networks, which are described as a subform of artificial neural networks. They are organized in different or multiple "layers" in the artificial neural network, with the input layer receiving the raw input data from the user and the output layer creating the output prediction.', 'source_documents': [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]}}
<class 'dict'>


result keys: dict_keys(['question', 'result'])


result["result"]["source_documents"]
 [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]


result["result"]["source_documents"][0]
 page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden' metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}
<class 'langchain.schema.document.Document'>


result["result"]["source_documents"][0].page_content
 für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller 

Übersetzungen oder zur Sprach- und Textgenerierung.

Technisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als 

Unterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large 

Language Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren 

sich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des 

menschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten 

verarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im 

künstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei 

der Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die 

Ausgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden
<class 'str'>
result:
 {'question': 'For what are LLM being used?', 'result': {'answer': ' Large language models are used for processing speech or text inputs, such as in the context of machine translations or for speech and text generation.', 'source_documents': [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]}}
<class 'dict'>


result keys: dict_keys(['question', 'result'])


result["result"]["source_documents"]
 [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]


result["result"]["source_documents"][0]
 page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden' metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}
<class 'langchain.schema.document.Document'>


result["result"]["source_documents"][0].page_content
 für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller 

Übersetzungen oder zur Sprach- und Textgenerierung.

Technisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als 

Unterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large 

Language Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren 

sich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des 

menschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten 

verarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im 

künstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei 

der Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die 

Ausgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden
<class 'str'>
result:
 {'question': 'Why are LLM beneficial for being used to decipher speech?', 'result': {'answer': ' Large language models can be used to generate text that is similar to human speech, which can be useful in supporting human activities. They can also be used to create text-in-image or text-in-audio applications.', 'source_documents': [Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='zu erwarten, die Texteingabedaten mit Bild- und Audiodaten verknüpfen. Auch scheinen Large \n\nLanguage Models vermehrt auf den Markt zu kommen, die ausschließlich dafür verwendet werden, \n\nsynthetische Daten für das Training anderer maschineller Lernmodelle zu erzeugen (sog. data \n\naugmentation), was etwa in der medizinischen Forschung nützlich sein kann, wenn die realen \n\nDatenlage begrenzt ist.\n\n5 von 6\n\n1/26/2023\n\nhttp://beck-online.beck.de/Bcid/Y-300-Z-MMRAktuell-B-2023-N-455171\n\n \n \n \n \n \n\x0cHinsichtlich der regulatorischen Berücksichtigung von Large Language Models im DSA und den \n\naktuellen Entwürfen zum AI-Act finden sich im Ergebnis nur wenige Bestimmungen, welche diese \n\noder deren Erzeugnisse direkt adressieren bzw. regulieren würden. Während im Rahmen Letzteren \n\nnoch unklar scheint, inwiefern Large Language Models bzw. GPAI’s überhaupt unmittelbar reguliert \n\nwerden sollen, beinhaltet der DSA zwar partiell wichtige Ergänzungen und Transparenzinstrumente,', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='kompetenzrechtlich vorgesehen ist zu entscheiden, welche Inhalte unter einen Deepfake fallen und \n\nwie die in Art. 52 Abs. 3 AIA-E beinhalteten Ausnahmen zu Zwecken der Ausübung der Meinungs-, \n\nKunst- oder Wissenschaftsfreiheit auszulegen sind (hierzu u.a. Hinderks ZUM 2022, 110 (114)). \n\nMöglicherweise soll an dieser Stelle auch an Art. 69 AIA-E angeknüpft werden, der darauf abzielt, \n\nVerhaltenskodizes als Mittel zur freiwilligen Einhaltung der Anforderungen des AIA-E für nicht-\n\nhochriskante KI-Systeme zu etablieren.\n\nIV. Zusammenfassung und Ausblick\n\nLarge Language Models liefern bereits heute teils beeindruckende Ergebnisse im Bereich der Text- \n\nund Sprachgenerierung, was menschliche Tätigkeiten sinnvoll unterstützen kann. Gerade neuere \n\nLarge Language Models wie Dall-E zeigen jedoch, dass auch darüberhinausgehende Use-Cases \n\ndenkbar sind. So sind in der Zukunft gerade bessere Text-in-Bild- oder Text-in-Audio-Anwendungen', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]}}
<class 'dict'>


result keys: dict_keys(['question', 'result'])


result["result"]["source_documents"]
 [Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='zu erwarten, die Texteingabedaten mit Bild- und Audiodaten verknüpfen. Auch scheinen Large \n\nLanguage Models vermehrt auf den Markt zu kommen, die ausschließlich dafür verwendet werden, \n\nsynthetische Daten für das Training anderer maschineller Lernmodelle zu erzeugen (sog. data \n\naugmentation), was etwa in der medizinischen Forschung nützlich sein kann, wenn die realen \n\nDatenlage begrenzt ist.\n\n5 von 6\n\n1/26/2023\n\nhttp://beck-online.beck.de/Bcid/Y-300-Z-MMRAktuell-B-2023-N-455171\n\n \n \n \n \n \n\x0cHinsichtlich der regulatorischen Berücksichtigung von Large Language Models im DSA und den \n\naktuellen Entwürfen zum AI-Act finden sich im Ergebnis nur wenige Bestimmungen, welche diese \n\noder deren Erzeugnisse direkt adressieren bzw. regulieren würden. Während im Rahmen Letzteren \n\nnoch unklar scheint, inwiefern Large Language Models bzw. GPAI’s überhaupt unmittelbar reguliert \n\nwerden sollen, beinhaltet der DSA zwar partiell wichtige Ergänzungen und Transparenzinstrumente,', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='kompetenzrechtlich vorgesehen ist zu entscheiden, welche Inhalte unter einen Deepfake fallen und \n\nwie die in Art. 52 Abs. 3 AIA-E beinhalteten Ausnahmen zu Zwecken der Ausübung der Meinungs-, \n\nKunst- oder Wissenschaftsfreiheit auszulegen sind (hierzu u.a. Hinderks ZUM 2022, 110 (114)). \n\nMöglicherweise soll an dieser Stelle auch an Art. 69 AIA-E angeknüpft werden, der darauf abzielt, \n\nVerhaltenskodizes als Mittel zur freiwilligen Einhaltung der Anforderungen des AIA-E für nicht-\n\nhochriskante KI-Systeme zu etablieren.\n\nIV. Zusammenfassung und Ausblick\n\nLarge Language Models liefern bereits heute teils beeindruckende Ergebnisse im Bereich der Text- \n\nund Sprachgenerierung, was menschliche Tätigkeiten sinnvoll unterstützen kann. Gerade neuere \n\nLarge Language Models wie Dall-E zeigen jedoch, dass auch darüberhinausgehende Use-Cases \n\ndenkbar sind. So sind in der Zukunft gerade bessere Text-in-Bild- oder Text-in-Audio-Anwendungen', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]


result["result"]["source_documents"][0]
 page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht' metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}
<class 'langchain.schema.document.Document'>


result["result"]["source_documents"][0].page_content
 Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-

E zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären 

Anwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund 

sekundärer Anwendungsbereiche, zu denken.

II. Problemkreise von Large Language Models und deren Erzeugnissen

Bezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur 

überblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger 

et al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt 

bereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte 

Text unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das 

Sprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht
<class 'str'>
result:
 {'question': 'What is a large', 'result': {'answer': ' A large language model is a type of artificial neural network that is used to process speech or text inputs, such as in the context of machine translations or for speech and text generation. They often work on the basis of feedforward networks, which are described as a subform of artificial neural networks. They are organized in different or multiple "layers" in the artificial neural network, with the input layer receiving the raw input data from the user and the output layer creating the output prediction.', 'source_documents': [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]}}
<class 'dict'>


result keys: dict_keys(['question', 'result'])


result["result"]["source_documents"]
 [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]


result["result"]["source_documents"][0]
 page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden' metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}
<class 'langchain.schema.document.Document'>


result["result"]["source_documents"][0].page_content
 für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller 

Übersetzungen oder zur Sprach- und Textgenerierung.

Technisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als 

Unterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large 

Language Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren 

sich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des 

menschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten 

verarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im 

künstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei 

der Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die 

Ausgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden
<class 'str'>
result:
 {'question': 'How does it use a feedforward network?', 'result': {'answer': ' A large language model typically uses a feedforward network as a subform of artificial neural networks. The feedforward network is organized into different layers, with the input layer receiving raw input data from the user and the output layer creating a prediction. The layers in between process and connect the data.', 'source_documents': [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='vorkommen, oder weil das System versucht, einen Text zu generieren, der zu lang oder zu komplex \n\nfür seine derzeitigen Fähigkeiten ist.\n\nEin weiteres mögliches Problem ist, dass der generierte Text voreingenommene, beleidigende oder \n\ndiskriminierende Inhalte enthalten kann. Dies geschieht zB dann, wenn das Modell einseitige Muster \n\naus nicht-repräsentativen Trainingsdaten gelernt hat oder wenn es Text auf der Grundlage \n\nunvollständiger oder irreführender Eingaben generiert (Brown et al., Language Models are Few-\n\nShot Learners, NeurIPS, 2020; Bender et al\n\n, On the Dangers of Stochastic Parrots: Can Language \n\nModels Be Too Big?, FAccT 2021, 610–623).\n\nDarüber hinaus kann das Trainieren von Large Language Models, in Abhängigkeit zu seiner Größe, \n\n.\n\nArchitektur und verwendeter Hardware, viele Rechenressourcen und damit Energie erfordern, was \n\nim Kontext von Energieknappheit und Klimaneutralität ein Nachteil ihrer Verwendung und', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Plattform verwendet werden, um auf ihrer Online-Schnittstelle den Nutzern bestimmte \n\nInformationen vorzuschlagen oder diese Informationen zu priorisieren“. Zwar vermögen Large \n\nLanguage Models nach etwaiger Texteingabe als zumindest teilweise automatisiert ablaufend \n\nbetrachtet werden, jedoch basieren sie in der Praxis regelmäßig (noch) auf einer gewissen \n\nMitwirkungshandlung des interagierenden Nutzers, welche in der Definition gerade nicht abgebildet \n\nwird. Dies macht die Anwendung von Art. 27 DSA auf Large Language Models zumindest holprig, da \n\nvielmehr vom Betreiber einer Online-Plattform aus gedacht wird. Eindeutiger könnten daher Large \n\nLanguage Models unter Art. 27 DSA fallen, bei denen der jeweilige Input Layer sich aus zuvor über \n\ndie Online-Plattform erhobenen (personenbezogenen oder nicht-personenbezogenen) Daten „selbst \n\nbedient“ und hierauf basierend etwa Werbung mit für den jeweiligen Nutzer besonders \n\nansprechendem Werbetext schaltet.', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]}}
<class 'dict'>


result keys: dict_keys(['question', 'result'])


result["result"]["source_documents"]
 [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='vorkommen, oder weil das System versucht, einen Text zu generieren, der zu lang oder zu komplex \n\nfür seine derzeitigen Fähigkeiten ist.\n\nEin weiteres mögliches Problem ist, dass der generierte Text voreingenommene, beleidigende oder \n\ndiskriminierende Inhalte enthalten kann. Dies geschieht zB dann, wenn das Modell einseitige Muster \n\naus nicht-repräsentativen Trainingsdaten gelernt hat oder wenn es Text auf der Grundlage \n\nunvollständiger oder irreführender Eingaben generiert (Brown et al., Language Models are Few-\n\nShot Learners, NeurIPS, 2020; Bender et al\n\n, On the Dangers of Stochastic Parrots: Can Language \n\nModels Be Too Big?, FAccT 2021, 610–623).\n\nDarüber hinaus kann das Trainieren von Large Language Models, in Abhängigkeit zu seiner Größe, \n\n.\n\nArchitektur und verwendeter Hardware, viele Rechenressourcen und damit Energie erfordern, was \n\nim Kontext von Energieknappheit und Klimaneutralität ein Nachteil ihrer Verwendung und', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Plattform verwendet werden, um auf ihrer Online-Schnittstelle den Nutzern bestimmte \n\nInformationen vorzuschlagen oder diese Informationen zu priorisieren“. Zwar vermögen Large \n\nLanguage Models nach etwaiger Texteingabe als zumindest teilweise automatisiert ablaufend \n\nbetrachtet werden, jedoch basieren sie in der Praxis regelmäßig (noch) auf einer gewissen \n\nMitwirkungshandlung des interagierenden Nutzers, welche in der Definition gerade nicht abgebildet \n\nwird. Dies macht die Anwendung von Art. 27 DSA auf Large Language Models zumindest holprig, da \n\nvielmehr vom Betreiber einer Online-Plattform aus gedacht wird. Eindeutiger könnten daher Large \n\nLanguage Models unter Art. 27 DSA fallen, bei denen der jeweilige Input Layer sich aus zuvor über \n\ndie Online-Plattform erhobenen (personenbezogenen oder nicht-personenbezogenen) Daten „selbst \n\nbedient“ und hierauf basierend etwa Werbung mit für den jeweiligen Nutzer besonders \n\nansprechendem Werbetext schaltet.', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]


result["result"]["source_documents"][0]
 page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden' metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}
<class 'langchain.schema.document.Document'>


result["result"]["source_documents"][0].page_content
 für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller 

Übersetzungen oder zur Sprach- und Textgenerierung.

Technisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als 

Unterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large 

Language Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren 

sich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des 

menschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten 

verarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im 

künstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei 

der Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die 

Ausgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden
<class 'str'>
result:
 {'question': 'How many layers are being used?', 'result': {'answer': ' There are three layers present in the feedforward network of a large language model: the input layer, the hidden layers, and the output layer.', 'source_documents': [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Layers, die die Eingabedaten verarbeiten und das Ausgabeergebnis an den Output Layer \n\nweiterleiten. Die erzeugte Ausgabe im Output Layer basiert dabei maßgeblich auf den vorhandenen \n\nneuronalen Verknüpfungen in den Hidden Layers sowie deren erlernter Gewichtung untereinander \n\nbei gewissen Eingaben. Insbesondere der (meist automatisierten und algorithmusbasierten) \n\nAnpassung der Gewichtungen zwischen den neuronalen Verknüpfungen in den Hidden Layers \n\nkommt daher bei der Fehlerminimierung sowie dem Training von ausgegebenen Informationen, \n\nVorhersagen oder Klassifikationen der Large Language Models entscheidende Bedeutung zu (zu den \n\nbekanntesten Optimierungsalgorithmen für Large Language Models gehören dabei Stochastic \n\nGradient Descent, Adam, AdaGrad oder RMSProp).\n\n1 von 6\n\n1/26/2023\n\nhttp://beck-online.beck.de/Bcid/Y-300-Z-MMRAktuell-B-2023-N-455171\n\n \n \n\x0cIn Verbindung mit großen Sets an Bild- oder Audiodaten können Large Language Models zudem für', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='vorkommen, oder weil das System versucht, einen Text zu generieren, der zu lang oder zu komplex \n\nfür seine derzeitigen Fähigkeiten ist.\n\nEin weiteres mögliches Problem ist, dass der generierte Text voreingenommene, beleidigende oder \n\ndiskriminierende Inhalte enthalten kann. Dies geschieht zB dann, wenn das Modell einseitige Muster \n\naus nicht-repräsentativen Trainingsdaten gelernt hat oder wenn es Text auf der Grundlage \n\nunvollständiger oder irreführender Eingaben generiert (Brown et al., Language Models are Few-\n\nShot Learners, NeurIPS, 2020; Bender et al\n\n, On the Dangers of Stochastic Parrots: Can Language \n\nModels Be Too Big?, FAccT 2021, 610–623).\n\nDarüber hinaus kann das Trainieren von Large Language Models, in Abhängigkeit zu seiner Größe, \n\n.\n\nArchitektur und verwendeter Hardware, viele Rechenressourcen und damit Energie erfordern, was \n\nim Kontext von Energieknappheit und Klimaneutralität ein Nachteil ihrer Verwendung und', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]}}
<class 'dict'>


result keys: dict_keys(['question', 'result'])


result["result"]["source_documents"]
 [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Layers, die die Eingabedaten verarbeiten und das Ausgabeergebnis an den Output Layer \n\nweiterleiten. Die erzeugte Ausgabe im Output Layer basiert dabei maßgeblich auf den vorhandenen \n\nneuronalen Verknüpfungen in den Hidden Layers sowie deren erlernter Gewichtung untereinander \n\nbei gewissen Eingaben. Insbesondere der (meist automatisierten und algorithmusbasierten) \n\nAnpassung der Gewichtungen zwischen den neuronalen Verknüpfungen in den Hidden Layers \n\nkommt daher bei der Fehlerminimierung sowie dem Training von ausgegebenen Informationen, \n\nVorhersagen oder Klassifikationen der Large Language Models entscheidende Bedeutung zu (zu den \n\nbekanntesten Optimierungsalgorithmen für Large Language Models gehören dabei Stochastic \n\nGradient Descent, Adam, AdaGrad oder RMSProp).\n\n1 von 6\n\n1/26/2023\n\nhttp://beck-online.beck.de/Bcid/Y-300-Z-MMRAktuell-B-2023-N-455171\n\n \n \n\x0cIn Verbindung mit großen Sets an Bild- oder Audiodaten können Large Language Models zudem für', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='vorkommen, oder weil das System versucht, einen Text zu generieren, der zu lang oder zu komplex \n\nfür seine derzeitigen Fähigkeiten ist.\n\nEin weiteres mögliches Problem ist, dass der generierte Text voreingenommene, beleidigende oder \n\ndiskriminierende Inhalte enthalten kann. Dies geschieht zB dann, wenn das Modell einseitige Muster \n\naus nicht-repräsentativen Trainingsdaten gelernt hat oder wenn es Text auf der Grundlage \n\nunvollständiger oder irreführender Eingaben generiert (Brown et al., Language Models are Few-\n\nShot Learners, NeurIPS, 2020; Bender et al\n\n, On the Dangers of Stochastic Parrots: Can Language \n\nModels Be Too Big?, FAccT 2021, 610–623).\n\nDarüber hinaus kann das Trainieren von Large Language Models, in Abhängigkeit zu seiner Größe, \n\n.\n\nArchitektur und verwendeter Hardware, viele Rechenressourcen und damit Energie erfordern, was \n\nim Kontext von Energieknappheit und Klimaneutralität ein Nachteil ihrer Verwendung und', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]


result["result"]["source_documents"][0]
 page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden' metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}
<class 'langchain.schema.document.Document'>


result["result"]["source_documents"][0].page_content
 für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller 

Übersetzungen oder zur Sprach- und Textgenerierung.

Technisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als 

Unterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large 

Language Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren 

sich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des 

menschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten 

verarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im 

künstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei 

der Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die 

Ausgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden
<class 'str'>
result:
 {'question': 'What is a large language model?', 'result': {'answer': ' A large language model is a type of artificial neural network that is used to process language or text inputs, such as in the context of machine translation or for language and text generation. They often work on the basis of feedforward networks, which are described as a subform of artificial neural networks. They are organized in different or multiple "layers" in the artificial neural network, with the input layer receiving the raw input data from the user and the output layer creating the output prediction.', 'source_documents': [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]}}
<class 'dict'>


result keys: dict_keys(['question', 'result'])


result["result"]["source_documents"]
 [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]


result["result"]["source_documents"][0]
 page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden' metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}
<class 'langchain.schema.document.Document'>


result["result"]["source_documents"][0].page_content
 für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller 

Übersetzungen oder zur Sprach- und Textgenerierung.

Technisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als 

Unterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large 

Language Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren 

sich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des 

menschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten 

verarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im 

künstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei 

der Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die 

Ausgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden
<class 'str'>
result:
 {'question': 'How is text being processed?', 'result': {'answer': ' Large language models typically use feedforward networks, which are a type of artificial neural network. These networks are organized into different layers, with the input layer receiving raw input data from the user and the output layer creating a prediction. The hidden layers in between process and connect the data.', 'source_documents': [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='vorkommen, oder weil das System versucht, einen Text zu generieren, der zu lang oder zu komplex \n\nfür seine derzeitigen Fähigkeiten ist.\n\nEin weiteres mögliches Problem ist, dass der generierte Text voreingenommene, beleidigende oder \n\ndiskriminierende Inhalte enthalten kann. Dies geschieht zB dann, wenn das Modell einseitige Muster \n\naus nicht-repräsentativen Trainingsdaten gelernt hat oder wenn es Text auf der Grundlage \n\nunvollständiger oder irreführender Eingaben generiert (Brown et al., Language Models are Few-\n\nShot Learners, NeurIPS, 2020; Bender et al\n\n, On the Dangers of Stochastic Parrots: Can Language \n\nModels Be Too Big?, FAccT 2021, 610–623).\n\nDarüber hinaus kann das Trainieren von Large Language Models, in Abhängigkeit zu seiner Größe, \n\n.\n\nArchitektur und verwendeter Hardware, viele Rechenressourcen und damit Energie erfordern, was \n\nim Kontext von Energieknappheit und Klimaneutralität ein Nachteil ihrer Verwendung und', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='zu erwarten, die Texteingabedaten mit Bild- und Audiodaten verknüpfen. Auch scheinen Large \n\nLanguage Models vermehrt auf den Markt zu kommen, die ausschließlich dafür verwendet werden, \n\nsynthetische Daten für das Training anderer maschineller Lernmodelle zu erzeugen (sog. data \n\naugmentation), was etwa in der medizinischen Forschung nützlich sein kann, wenn die realen \n\nDatenlage begrenzt ist.\n\n5 von 6\n\n1/26/2023\n\nhttp://beck-online.beck.de/Bcid/Y-300-Z-MMRAktuell-B-2023-N-455171\n\n \n \n \n \n \n\x0cHinsichtlich der regulatorischen Berücksichtigung von Large Language Models im DSA und den \n\naktuellen Entwürfen zum AI-Act finden sich im Ergebnis nur wenige Bestimmungen, welche diese \n\noder deren Erzeugnisse direkt adressieren bzw. regulieren würden. Während im Rahmen Letzteren \n\nnoch unklar scheint, inwiefern Large Language Models bzw. GPAI’s überhaupt unmittelbar reguliert \n\nwerden sollen, beinhaltet der DSA zwar partiell wichtige Ergänzungen und Transparenzinstrumente,', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]}}
<class 'dict'>


result keys: dict_keys(['question', 'result'])


result["result"]["source_documents"]
 [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='vorkommen, oder weil das System versucht, einen Text zu generieren, der zu lang oder zu komplex \n\nfür seine derzeitigen Fähigkeiten ist.\n\nEin weiteres mögliches Problem ist, dass der generierte Text voreingenommene, beleidigende oder \n\ndiskriminierende Inhalte enthalten kann. Dies geschieht zB dann, wenn das Modell einseitige Muster \n\naus nicht-repräsentativen Trainingsdaten gelernt hat oder wenn es Text auf der Grundlage \n\nunvollständiger oder irreführender Eingaben generiert (Brown et al., Language Models are Few-\n\nShot Learners, NeurIPS, 2020; Bender et al\n\n, On the Dangers of Stochastic Parrots: Can Language \n\nModels Be Too Big?, FAccT 2021, 610–623).\n\nDarüber hinaus kann das Trainieren von Large Language Models, in Abhängigkeit zu seiner Größe, \n\n.\n\nArchitektur und verwendeter Hardware, viele Rechenressourcen und damit Energie erfordern, was \n\nim Kontext von Energieknappheit und Klimaneutralität ein Nachteil ihrer Verwendung und', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='zu erwarten, die Texteingabedaten mit Bild- und Audiodaten verknüpfen. Auch scheinen Large \n\nLanguage Models vermehrt auf den Markt zu kommen, die ausschließlich dafür verwendet werden, \n\nsynthetische Daten für das Training anderer maschineller Lernmodelle zu erzeugen (sog. data \n\naugmentation), was etwa in der medizinischen Forschung nützlich sein kann, wenn die realen \n\nDatenlage begrenzt ist.\n\n5 von 6\n\n1/26/2023\n\nhttp://beck-online.beck.de/Bcid/Y-300-Z-MMRAktuell-B-2023-N-455171\n\n \n \n \n \n \n\x0cHinsichtlich der regulatorischen Berücksichtigung von Large Language Models im DSA und den \n\naktuellen Entwürfen zum AI-Act finden sich im Ergebnis nur wenige Bestimmungen, welche diese \n\noder deren Erzeugnisse direkt adressieren bzw. regulieren würden. Während im Rahmen Letzteren \n\nnoch unklar scheint, inwiefern Large Language Models bzw. GPAI’s überhaupt unmittelbar reguliert \n\nwerden sollen, beinhaltet der DSA zwar partiell wichtige Ergänzungen und Transparenzinstrumente,', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]


result["result"]["source_documents"][0]
 page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden' metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}
<class 'langchain.schema.document.Document'>


result["result"]["source_documents"][0].page_content
 für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller 

Übersetzungen oder zur Sprach- und Textgenerierung.

Technisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als 

Unterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large 

Language Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren 

sich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des 

menschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten 

verarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im 

künstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei 

der Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die 

Ausgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden
<class 'str'>
result:
 {'question': 'What is a large language model and how advanced is it?', 'result': {'answer': '\nA large language model is a type of artificial neural network that is used to process language or text inputs, such as for machine translation or for language and text generation. It is based on the architecture of feedforward networks, which are a type of artificial neural network, and is organized into different layers. It is quite advanced, as it is able to generate text that is similar to that written by humans.', 'source_documents': [Document(page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]}}
<class 'dict'>


result keys: dict_keys(['question', 'result'])


result["result"]["source_documents"]
 [Document(page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]


result["result"]["source_documents"][0]
 page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).' metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}
<class 'langchain.schema.document.Document'>


result["result"]["source_documents"][0].page_content
 Redaktion MMR-Aktuell

Kurzbeiträge/Kommentare

MMR-Aktuell 2023, 455171

Regulierung von Large Language Models in DSA und AIA-E

Alexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und 

Datenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-

Universität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer 

Technologien sowie Datenrecht (ForTech) e.V.

Die Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich 

doch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die 

genaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere 

aufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem 

Leser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).
<class 'str'>
result:
 {'question': 'How many hidden layers does an average LLM install?', 'result': {'answer': ' Large language models typically include multiple hidden layers between the input and output layers.', 'source_documents': [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Layers, die die Eingabedaten verarbeiten und das Ausgabeergebnis an den Output Layer \n\nweiterleiten. Die erzeugte Ausgabe im Output Layer basiert dabei maßgeblich auf den vorhandenen \n\nneuronalen Verknüpfungen in den Hidden Layers sowie deren erlernter Gewichtung untereinander \n\nbei gewissen Eingaben. Insbesondere der (meist automatisierten und algorithmusbasierten) \n\nAnpassung der Gewichtungen zwischen den neuronalen Verknüpfungen in den Hidden Layers \n\nkommt daher bei der Fehlerminimierung sowie dem Training von ausgegebenen Informationen, \n\nVorhersagen oder Klassifikationen der Large Language Models entscheidende Bedeutung zu (zu den \n\nbekanntesten Optimierungsalgorithmen für Large Language Models gehören dabei Stochastic \n\nGradient Descent, Adam, AdaGrad oder RMSProp).\n\n1 von 6\n\n1/26/2023\n\nhttp://beck-online.beck.de/Bcid/Y-300-Z-MMRAktuell-B-2023-N-455171\n\n \n \n\x0cIn Verbindung mit großen Sets an Bild- oder Audiodaten können Large Language Models zudem für', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]}}
<class 'dict'>


result keys: dict_keys(['question', 'result'])


result["result"]["source_documents"]
 [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Layers, die die Eingabedaten verarbeiten und das Ausgabeergebnis an den Output Layer \n\nweiterleiten. Die erzeugte Ausgabe im Output Layer basiert dabei maßgeblich auf den vorhandenen \n\nneuronalen Verknüpfungen in den Hidden Layers sowie deren erlernter Gewichtung untereinander \n\nbei gewissen Eingaben. Insbesondere der (meist automatisierten und algorithmusbasierten) \n\nAnpassung der Gewichtungen zwischen den neuronalen Verknüpfungen in den Hidden Layers \n\nkommt daher bei der Fehlerminimierung sowie dem Training von ausgegebenen Informationen, \n\nVorhersagen oder Klassifikationen der Large Language Models entscheidende Bedeutung zu (zu den \n\nbekanntesten Optimierungsalgorithmen für Large Language Models gehören dabei Stochastic \n\nGradient Descent, Adam, AdaGrad oder RMSProp).\n\n1 von 6\n\n1/26/2023\n\nhttp://beck-online.beck.de/Bcid/Y-300-Z-MMRAktuell-B-2023-N-455171\n\n \n \n\x0cIn Verbindung mit großen Sets an Bild- oder Audiodaten können Large Language Models zudem für', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]


result["result"]["source_documents"][0]
 page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden' metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}
<class 'langchain.schema.document.Document'>


result["result"]["source_documents"][0].page_content
 für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller 

Übersetzungen oder zur Sprach- und Textgenerierung.

Technisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als 

Unterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large 

Language Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren 

sich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des 

menschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten 

verarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im 

künstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei 

der Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die 

Ausgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden
<class 'str'>
result:
 {'question': 'How many hidden layers does an average LLM install?', 'result': {'answer': ' Large language models typically include multiple hidden layers between the input and output layers.', 'source_documents': [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Layers, die die Eingabedaten verarbeiten und das Ausgabeergebnis an den Output Layer \n\nweiterleiten. Die erzeugte Ausgabe im Output Layer basiert dabei maßgeblich auf den vorhandenen \n\nneuronalen Verknüpfungen in den Hidden Layers sowie deren erlernter Gewichtung untereinander \n\nbei gewissen Eingaben. Insbesondere der (meist automatisierten und algorithmusbasierten) \n\nAnpassung der Gewichtungen zwischen den neuronalen Verknüpfungen in den Hidden Layers \n\nkommt daher bei der Fehlerminimierung sowie dem Training von ausgegebenen Informationen, \n\nVorhersagen oder Klassifikationen der Large Language Models entscheidende Bedeutung zu (zu den \n\nbekanntesten Optimierungsalgorithmen für Large Language Models gehören dabei Stochastic \n\nGradient Descent, Adam, AdaGrad oder RMSProp).\n\n1 von 6\n\n1/26/2023\n\nhttp://beck-online.beck.de/Bcid/Y-300-Z-MMRAktuell-B-2023-N-455171\n\n \n \n\x0cIn Verbindung mit großen Sets an Bild- oder Audiodaten können Large Language Models zudem für', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]}}
<class 'dict'>


result keys: dict_keys(['question', 'result'])


result["result"]["source_documents"]
 [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Layers, die die Eingabedaten verarbeiten und das Ausgabeergebnis an den Output Layer \n\nweiterleiten. Die erzeugte Ausgabe im Output Layer basiert dabei maßgeblich auf den vorhandenen \n\nneuronalen Verknüpfungen in den Hidden Layers sowie deren erlernter Gewichtung untereinander \n\nbei gewissen Eingaben. Insbesondere der (meist automatisierten und algorithmusbasierten) \n\nAnpassung der Gewichtungen zwischen den neuronalen Verknüpfungen in den Hidden Layers \n\nkommt daher bei der Fehlerminimierung sowie dem Training von ausgegebenen Informationen, \n\nVorhersagen oder Klassifikationen der Large Language Models entscheidende Bedeutung zu (zu den \n\nbekanntesten Optimierungsalgorithmen für Large Language Models gehören dabei Stochastic \n\nGradient Descent, Adam, AdaGrad oder RMSProp).\n\n1 von 6\n\n1/26/2023\n\nhttp://beck-online.beck.de/Bcid/Y-300-Z-MMRAktuell-B-2023-N-455171\n\n \n \n\x0cIn Verbindung mit großen Sets an Bild- oder Audiodaten können Large Language Models zudem für', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]


result["result"]["source_documents"][0]
 page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden' metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}
<class 'langchain.schema.document.Document'>


result["result"]["source_documents"][0].page_content
 für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller 

Übersetzungen oder zur Sprach- und Textgenerierung.

Technisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als 

Unterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large 

Language Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren 

sich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des 

menschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten 

verarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im 

künstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei 

der Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die 

Ausgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden
<class 'str'>
result:
 {'question': 'What is a large language model?', 'result': {'answer': ' A large language model is a type of artificial neural network that is used to process language or text inputs, such as in the context of machine translation or for language and text generation. They often work on the basis of feedforward networks, which are described as a subform of artificial neural networks. They are organized in different or multiple "layers" in the artificial neural network, with the input layer receiving the raw input data from the user and the output layer creating the output prediction.', 'source_documents': [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]}}
<class 'dict'>


result keys: dict_keys(['question', 'result'])


result["result"]["source_documents"]
 [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Redaktion MMR-Aktuell\n\nKurzbeiträge/Kommentare\n\nMMR-Aktuell 2023, 455171\n\nRegulierung von Large Language Models in DSA und AIA-E\n\nAlexander Wehde ist studentische Hilfskraft am Lehrstuhl für Bürgerliches Recht, Informations- und \n\nDatenrecht bei Prof. Dr. Louisa Specht-Riemenschneider an der Rheinischen-Friedrich-Wilhelms-\n\nUniversität Bonn und stellv. Vorstandsvorsitzender der Forschungsstelle für Rechtsfragen neuer \n\nTechnologien sowie Datenrecht (ForTech) e.V.\n\nDie Regulierung großer Sprachmodelle (engl. Large Language Models) ist diffizil, befindet sie sich \n\ndoch im Spannungsfeld von Innovationsförderung und mannigfaltigen Befürchtungen über die \n\ngenaue Verwendung sowie Ausgestaltung solcher Systeme. Letztere erwachsen dabei insbesondere \n\naufgrund der Tatsache, dass Large Language Models in der Lage sind, Text zu erzeugen, der dem \n\nLeser den Eindruck vermitteln mag von Menschen geschriebener Text läge vor (sog. ELIZA-Effekt).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]


result["result"]["source_documents"][0]
 page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden' metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}
<class 'langchain.schema.document.Document'>


result["result"]["source_documents"][0].page_content
 für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller 

Übersetzungen oder zur Sprach- und Textgenerierung.

Technisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als 

Unterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large 

Language Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren 

sich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des 

menschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten 

verarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im 

künstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei 

der Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die 

Ausgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden
<class 'str'>
result:
 {'question': 'How does it use a artificial neural network?', 'result': {'answer': ' A large language model typically uses a feedforward network, which is a type of artificial neural network. The artificial neural network consists of interconnected artificial neurons that process and link data. In the context of large language models, these neurons are organized in different or multiple "layers", with the input layer receiving the raw input data from the user and the output layer creating the output prediction.', 'source_documents': [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Plattform verwendet werden, um auf ihrer Online-Schnittstelle den Nutzern bestimmte \n\nInformationen vorzuschlagen oder diese Informationen zu priorisieren“. Zwar vermögen Large \n\nLanguage Models nach etwaiger Texteingabe als zumindest teilweise automatisiert ablaufend \n\nbetrachtet werden, jedoch basieren sie in der Praxis regelmäßig (noch) auf einer gewissen \n\nMitwirkungshandlung des interagierenden Nutzers, welche in der Definition gerade nicht abgebildet \n\nwird. Dies macht die Anwendung von Art. 27 DSA auf Large Language Models zumindest holprig, da \n\nvielmehr vom Betreiber einer Online-Plattform aus gedacht wird. Eindeutiger könnten daher Large \n\nLanguage Models unter Art. 27 DSA fallen, bei denen der jeweilige Input Layer sich aus zuvor über \n\ndie Online-Plattform erhobenen (personenbezogenen oder nicht-personenbezogenen) Daten „selbst \n\nbedient“ und hierauf basierend etwa Werbung mit für den jeweiligen Nutzer besonders \n\nansprechendem Werbetext schaltet.', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]}}
<class 'dict'>


result keys: dict_keys(['question', 'result'])


result["result"]["source_documents"]
 [Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Vor diesem Hintergrund stellt sich die Frage, inwieweit die angestrebte bzw. bereits verankerte \n\ndigitalpolitische Regulierung in Gestalt des Digital Services Act (DSA) und des Komissionsentwurfs \n\nzum Artificial Intelligence Act (AIA-E) Large Language Models angemessen berücksichtigen, um \n\neinen ethischen und verantwortungsbewussten Einsatz dieser in Zukunft sicherzustellen.\n\nI. Large Language Models\n\nLarge Language Models wie GPT-3, BERT oder Blender Bot 3 erfreuen sich dieser Tage großer \n\nAufmerksamkeit. Die Bezeichnung dieser als „large“ stellt dabei einen Rückbezug auf den sehr \n\ngroßen Datensatz anhand dessen das System trainiert wurde dar. Jener besteht oftmals aus \n\nMilliarden von Wörtern und Abfolgen dieser, was es den Large Language Models ermöglicht die \n\nMuster und Strukturen menschlicher Sprache verblüffend präzise zu erlernen und Text zu \n\ngenerieren, der dem eines Menschen ähnlich ist. Heute werden große Sprachmodelle daher häufig', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Plattform verwendet werden, um auf ihrer Online-Schnittstelle den Nutzern bestimmte \n\nInformationen vorzuschlagen oder diese Informationen zu priorisieren“. Zwar vermögen Large \n\nLanguage Models nach etwaiger Texteingabe als zumindest teilweise automatisiert ablaufend \n\nbetrachtet werden, jedoch basieren sie in der Praxis regelmäßig (noch) auf einer gewissen \n\nMitwirkungshandlung des interagierenden Nutzers, welche in der Definition gerade nicht abgebildet \n\nwird. Dies macht die Anwendung von Art. 27 DSA auf Large Language Models zumindest holprig, da \n\nvielmehr vom Betreiber einer Online-Plattform aus gedacht wird. Eindeutiger könnten daher Large \n\nLanguage Models unter Art. 27 DSA fallen, bei denen der jeweilige Input Layer sich aus zuvor über \n\ndie Online-Plattform erhobenen (personenbezogenen oder nicht-personenbezogenen) Daten „selbst \n\nbedient“ und hierauf basierend etwa Werbung mit für den jeweiligen Nutzer besonders \n\nansprechendem Werbetext schaltet.', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Text-in-Bild oder Text-in-Audio Transformationen eingesetzt werden, wie etwa die Anwendung Dall-\n\nE zeigt. Large Language Models sind daher nicht nur in ihrem (vermeintlich) primären \n\nAnwendungsbereich, der Sprach- und Textgenerierung, sondern auch vor dem Hintergrund \n\nsekundärer Anwendungsbereiche, zu denken.\n\nII. Problemkreise von Large Language Models und deren Erzeugnissen\n\nBezüglich der Verwendung von Large Language Models können mehrere Problemkreise, die hier nur \n\nüberblicksartig dargestellt werden können, identifiziert werden (umfassend betrachtend Weidinger \n\net al., Ethical and social risks of harm from Language Models, 2021). Ein zentrales Problem liegt \n\nbereits darin, dass – trotz häufig überwiegend guter Text- oder Sprachausgaben – der generierte \n\nText unsinnig sein oder grammatikalische Fehler enthalten kann. Dies kann passieren, wenn das \n\nSprachmodell in den Trainingsdaten Muster gelernt hat, die im realen Sprachgebrauch nicht', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'})]


result["result"]["source_documents"][0]
 page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden' metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}
<class 'langchain.schema.document.Document'>


result["result"]["source_documents"][0].page_content
 für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller 

Übersetzungen oder zur Sprach- und Textgenerierung.

Technisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als 

Unterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large 

Language Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren 

sich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des 

menschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten 

verarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im 

künstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei 

der Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die 

Ausgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden
<class 'str'>
result:
 {'question': 'What is a hidden layer?', 'chat_history': [], 'answer': ' A hidden layer is a layer in a feedforward network, which is a type of artificial neural network. It is located between the input layer and the output layer and is responsible for processing the input data and passing the output result to the output layer. The output generated in the output layer is largely based on the existing neural connections in the hidden layers and their learned weights with each other for certain inputs.', 'source_documents': [Document(page_content='Layers, die die Eingabedaten verarbeiten und das Ausgabeergebnis an den Output Layer \n\nweiterleiten. Die erzeugte Ausgabe im Output Layer basiert dabei maßgeblich auf den vorhandenen \n\nneuronalen Verknüpfungen in den Hidden Layers sowie deren erlernter Gewichtung untereinander \n\nbei gewissen Eingaben. Insbesondere der (meist automatisierten und algorithmusbasierten) \n\nAnpassung der Gewichtungen zwischen den neuronalen Verknüpfungen in den Hidden Layers \n\nkommt daher bei der Fehlerminimierung sowie dem Training von ausgegebenen Informationen, \n\nVorhersagen oder Klassifikationen der Large Language Models entscheidende Bedeutung zu (zu den \n\nbekanntesten Optimierungsalgorithmen für Large Language Models gehören dabei Stochastic \n\nGradient Descent, Adam, AdaGrad oder RMSProp).\n\n1 von 6\n\n1/26/2023\n\nhttp://beck-online.beck.de/Bcid/Y-300-Z-MMRAktuell-B-2023-N-455171\n\n \n \n\x0cIn Verbindung mit großen Sets an Bild- oder Audiodaten können Large Language Models zudem für', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='für die Verarbeitung von Sprach- oder Texteingaben verwendet, wie zB im Rahmen maschineller \n\nÜbersetzungen oder zur Sprach- und Textgenerierung.\n\nTechnisch arbeiten Large Language Models häufig auf Basis sog. Feedforward Networks, die als \n\nUnterform künstlicher neuronaler Netzwerke beschrieben werden können (zur Architekur von Large \n\nLanguage Models etwa Vaswani et al., Attention Is All You Need, NIPS 2017). Als solche orientieren \n\nsich künstliche neuronale Netzwerke grundsätzlich am Erkenntnisstand der Arbeitsweise des \n\nmenschlichen Gehirns und bestehen aus miteinander verbundenen künstlichen Neuronen, die Daten \n\nverarbeiten und verknüpfen können. Im Kontext von Large Language Models sind diese im \n\nkünstlichen neuronalen Netzwerk in unterschiedlichen bzw. mehreren „Layern“ organisiert, wobei \n\nder Input Layer die rohen Eingabedaten des Nutzenden erhält und der Output Layer die \n\nAusgabevorhersage erstellt. Zwischen dem Input- und Output Layer liegen mehrere sog. Hidden', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='3 AIA-E fallen, kann unter Zuhilfenahme von Large Language Models, als Teilsystem von \n\nAnwendungen wie Dall-E, entstandenes Bild-, Audio- oder Videomaterial ein Deepfake darstellen.\n\nVor dem Hintergrund unterschiedlicher Auffassungen darüber, was ein KI-System bzw. Deepfakes \n\nauszeichnet, ist der Regulierungsansatz jedoch auch hinsichtlich seiner Regulierungssubjekte nicht \n\nunumstritten. Zwar scheint Einigkeit darüber zu bestehen, dass ein Deepfake zumindest die \n\nVerwendung von KI-basierter Technologie und die Absicht zu täuschen in sich trägt, doch sind \n\ndarüber hinaus gehende Charakteristiken zumeist mit praktischen Problemen verknüpft. So \n\nerscheinen insbesondere die Grenzen zwischen tiefgreifenden Fälschungen und simplen \n\naudiovisuellen Manipulationen schwierig zu ziehen (Paris/Donovan, Deepfakes and Cheap Fakes: \n\nThe Manipulation of Audio and Visual Evidence, 2019, S. 10 ff.).', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Regulierung_von_Large_Language_Models_in_DSA_und_AIA-E_-_beck-online.pdf'}), Document(page_content='Unser  Gehirn  ist  mit  der  Darstellung  von Wirkungskreisläufen,  die  zwischen  den \nVerbindungen dieser Treiber entstehen, sehr schnell überfordert. Sie bestimmen aber, ob \ndas System labil oder stabil ist, ob die Situation nur schwer oder ganz einfach verändert \nwerden kann, wieviel initiale Anschubkraft an welcher Stelle nötig ist, damit sich über-\nhaupt etwas bewegt, und in welchen Wirkungskreisläufen die mächtigen „Virtuous Circ-\nles“  oder  „Vicious  Circles“  verborgen  sind,  in  denen  die  größte  Gefahr,  aber  auch  die \ngrößten Hebel und die besten Ansätze für strategische Stoßrichtungen liegen. Auch hier \nkann und muss auf Computerunterstützung zurückgegriffen werden. Der MIT-Professor \n\n\x0c328', metadata={'source': '/Users/swmoeller/python/2023/large_language_model/BrainGPT/data/10_raw/doc2scan/Die Dritte Dimension - Martin Pfiffner.pdf'})]}
<class 'dict'>


result keys: dict_keys(['question', 'chat_history', 'answer', 'source_documents'])
