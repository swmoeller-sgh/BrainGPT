{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import openai # OpenAI library for working with OpenAI's GPT-3 or other models\n",
    "\n",
    "from langchain.vectorstores import Chroma  # Vector storage for langchain\n",
    "from langchain.embeddings import OpenAIEmbeddings  # Embeddings for langc\n",
    "\n",
    "import chromadb\n",
    "from chromadb.config import Settings # Importing a specific configuration settings modul\n",
    "\n",
    "ROOT_DIR = \"/Users/swmoeller/python/2023/large_language_model/BrainGPT\"\n",
    "PROCESSED_DATA_DIR = os.path.join(ROOT_DIR, str(os.getenv(\"PROCESSED_DATA_DIR\")))\n",
    "\n",
    "\n",
    "# [CONSTANTS definition]\n",
    "CHROMA_SETTINGS = Settings(\n",
    "        chroma_db_impl='duckdb+parquet',\n",
    "        persist_directory=PROCESSED_DATA_DIR,\n",
    "        anonymized_telemetry=False\n",
    ")\n",
    "\n",
    "# Initializing the vector store using OpenAI embeddings.\n",
    "embeddings = OpenAIEmbeddings()             # type: ignore\n",
    "\n",
    "in__datastore_location = PROCESSED_DATA_DIR\n",
    "in__embedding_function = embeddings\n",
    "in__chromadb_setting = CHROMA_SETTINGS\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# loading the vectorstore\n",
    "vectordb = Chroma(\n",
    "            persist_directory=in__datastore_location,\n",
    "            embedding_function=in__embedding_function,\n",
    "            client_settings=in__chromadb_setting\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/swmoeller/python/2023/large_language_model/BrainGPT/scripts/40_trials/reading_chromadb.ipynb Cell 3\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/swmoeller/python/2023/large_language_model/BrainGPT/scripts/40_trials/reading_chromadb.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Process and display the search results\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/swmoeller/python/2023/large_language_model/BrainGPT/scripts/40_trials/reading_chromadb.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m result \u001b[39min\u001b[39;00m results:\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/swmoeller/python/2023/large_language_model/BrainGPT/scripts/40_trials/reading_chromadb.ipynb#W1sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     collection_name \u001b[39m=\u001b[39m result[\u001b[39m'\u001b[39;49m\u001b[39mcollection\u001b[39;49m\u001b[39m'\u001b[39;49m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/swmoeller/python/2023/large_language_model/BrainGPT/scripts/40_trials/reading_chromadb.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     document_id \u001b[39m=\u001b[39m result[\u001b[39m'\u001b[39m\u001b[39mdocument_id\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/swmoeller/python/2023/large_language_model/BrainGPT/scripts/40_trials/reading_chromadb.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     similarity_score \u001b[39m=\u001b[39m result[\u001b[39m'\u001b[39m\u001b[39mscore\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# Perform similarity search across collections\n",
    "results = vectordb.similarity_search_with_score(\"what is a viable system model\", k=3)\n",
    "\n",
    "# Process and display the search results\n",
    "for result in results:\n",
    "    collection_name = result['collection']\n",
    "    document_id = result['document_id']\n",
    "    similarity_score = result['score']\n",
    "    print(f\"Collection: {collection_name}\")\n",
    "    print(f\"Document ID: {document_id}\")\n",
    "    print(f\"Similarity Score: {similarity_score}\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brainGPT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
